{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is HDF5?\n",
    "HDF5 stands for (**H**)eirarchical (**D**)ata (**F**)ormat, v**5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An HDF5 file is a container for two main kinds of objects:\n",
    "* datasets: array-like collections of data\n",
    "* groups: folder-like containers that hold datasets and other groups\n",
    "\n",
    "AND attributes: metadata on datasets or groups\n",
    "    \n",
    "The most fundamental thing to remember when using h5py is:\n",
    "\n",
    "**Datasets work like NumPy arrays and groups work like dictionaries**\n",
    "\n",
    "You should also remember:\n",
    "\n",
    "*Every object in an HDF5 file has a name, and theyâ€™re arranged in a POSIX-style hierarchy with /-separators*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with HDF5 in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "# Can also use HDF5 in PyTables, but won't be covered in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If installed Anaconda, simply\n",
    "       \n",
    "     conda install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "sm_array = np.random.random(size = (3,3))\n",
    "sml_array = np.random.random(size = (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating & handling HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create HDF5 file\n",
    "f = h5py.File(\"data.hdf5\", 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 files work like standard Python file objects, support standard modes, and should be closed when no longer in use.\n",
    "\n",
    "* 'r': Read only, file must exist\n",
    "* 'r+': Read/write, file must exist\n",
    "* 'w': Create file, truncate if exists\n",
    "* 'w-' or 'x': Create file, fail if exists\n",
    "* 'a': Read/write if exists, create otherwise (default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with datasets, groups, & attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "* Like NumPy arrays\n",
    "    * Collections of data elements\n",
    "    * Immutable datatype and (hyper)rectangular shape\n",
    "    * Descriptive attributes: shape, size, dtype\n",
    "    * Data slicing\n",
    "* Unlike NumPy arrays\n",
    "    * Compression\n",
    "    * Chunked-I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IPython reminder trick #1\n",
    "# Attributes & properties on an object (tab complete)\n",
    "#f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IPython reminder trick #2\n",
    "# See the docstring and all the details on an object by using the ?\n",
    "#f.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dataspace is (3, 3)\n",
      "Dataset datatype is float64\n",
      "Dataset name is /data\n",
      "Dataset is a member of the group <HDF5 group \"/\" (1 members)>\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset\n",
    "dataset = f.create_dataset(\"data\", data=sm_array)\n",
    "# Keywords shape and dtype may be specified along with data\n",
    "# If so, they will override data.shape and data.dtype\n",
    "print \"Dataset dataspace is\", dataset.shape\n",
    "print \"Dataset datatype is\", dataset.dtype\n",
    "print \"Dataset name is\", dataset.name\n",
    "print \"Dataset is a member of the group\", dataset.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dataspace is (2, 2)\n",
      "Dataset datatype is float64\n",
      "Dataset name is /sm_data\n",
      "Dataset is a member of the group <HDF5 group \"/\" (2 members)>\n"
     ]
    }
   ],
   "source": [
    "# Alternatively\n",
    "f['sm_data'] = sml_array\n",
    "dset = f['sm_data']\n",
    "print \"Dataset dataspace is\", dset.shape\n",
    "print \"Dataset datatype is\", dset.dtype\n",
    "print \"Dataset name is\", dset.name\n",
    "print \"Dataset is a member of the group\", dset.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/bin/h5dump\n",
      "HDF5 \"data.hdf5\" {\n",
      "GROUP \"/\" {\n",
      "   DATASET \"data\" {\n",
      "      DATATYPE  H5T_IEEE_F64LE\n",
      "      DATASPACE  SIMPLE { ( 3, 3 ) / ( 3, 3 ) }\n",
      "      DATA {\n",
      "      (0,0): 0.643312, 0.944549, 0.901227,\n",
      "      (1,0): 0.641839, 0.185239, 0.302659,\n",
      "      (2,0): 0.855635, 0.159378, 0.941674\n",
      "      }\n",
      "   }\n",
      "   DATASET \"sm_data\" {\n",
      "      DATATYPE  H5T_IEEE_F64LE\n",
      "      DATASPACE  SIMPLE { ( 2, 2 ) / ( 2, 2 ) }\n",
      "      DATA {\n",
      "      (0,0): 0.929715, 0.375441,\n",
      "      (1,0): 0.953104, 0.265835\n",
      "      }\n",
      "   }\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Command line utilities h5dump and h5stat useful to see info about file \n",
    "!which h5dump\n",
    "!h5dump data.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with subsets of data using NumPy syntax for data slicing\n",
    "f = h5py.File(\"data.hdf5\", 'w')\n",
    "f['intArray'] = np.ones((3,4))\n",
    "dset2 = f['intArray']\n",
    "dset2[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  2.,  2.],\n",
       "       [ 1.,  1.,  2.,  2.],\n",
       "       [ 1.,  1.,  2.,  2.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['intArray'][:,2:] = 2\n",
    "dset2[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groups\n",
    "* Like Python dictionaries\n",
    "    * keys - names of group members\n",
    "    * values - group members (either dataset or group objects)\n",
    "    * support iteration, indexing syntax, and standard exceptions\n",
    "* Objects in an HDF5 file can be stored in multiple groups    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "# File object is the *root group* and serves as entry point into the file.\n",
    "f = h5py.File('data.hdf5', 'w')\n",
    "print f.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group1\n"
     ]
    }
   ],
   "source": [
    "# Create a group\n",
    "grp = f.create_group(\"group1\")\n",
    "print grp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group1/subgrp\n"
     ]
    }
   ],
   "source": [
    "# Create a group within a group\n",
    "subgrp = grp.create_group(\"subgrp\")\n",
    "print subgrp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group2/subgrp2/anothergroup\n",
      "/group2/subgrp2\n"
     ]
    }
   ],
   "source": [
    "# Create groups implicitly\n",
    "grp2 = f.create_group(\"/group2/subgrp2/anothergroup\")\n",
    "print grp2.name\n",
    "grp3 = f['/group2/subgrp2']\n",
    "print grp3.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'group1', u'group2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'subgrp']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['group1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/group1/small'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group objects have create_* methods like files\n",
    "# Here, creating a dataset in a group\n",
    "dataset2 = grp.create_dataset(\"small\", data=sm_array)\n",
    "dataset2.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More ways to create a dataset in a group\n",
    "f['/group2/subgrp2/anothergroup/dset1'] = [4,4] # create dataset\n",
    "g = f['group2/subgrp2/anothergroup'] # create group\n",
    "g['dset2'] = [5,5] # create dataset in group\n",
    "dset3 = f.create_dataset('group2/dset3', data=[6,6]) # create dataset in group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 \"data.hdf5\" {\r\n",
      "GROUP \"/\" {\r\n",
      "   GROUP \"group1\" {\r\n",
      "      DATASET \"small\" {\r\n",
      "         DATATYPE  H5T_IEEE_F64LE\r\n",
      "         DATASPACE  SIMPLE { ( 3, 3 ) / ( 3, 3 ) }\r\n",
      "         DATA {\r\n",
      "         (0,0): 0.643312, 0.944549, 0.901227,\r\n",
      "         (1,0): 0.641839, 0.185239, 0.302659,\r\n",
      "         (2,0): 0.855635, 0.159378, 0.941674\r\n",
      "         }\r\n",
      "      }\r\n",
      "      GROUP \"subgrp\" {\r\n",
      "      }\r\n",
      "   }\r\n",
      "   GROUP \"group2\" {\r\n",
      "      DATASET \"dset3\" {\r\n",
      "         DATATYPE  H5T_STD_I64LE\r\n",
      "         DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }\r\n",
      "         DATA {\r\n",
      "         (0): 6, 6\r\n",
      "         }\r\n",
      "      }\r\n",
      "      GROUP \"subgrp2\" {\r\n",
      "         GROUP \"anothergroup\" {\r\n",
      "            DATASET \"dset1\" {\r\n",
      "               DATATYPE  H5T_STD_I64LE\r\n",
      "               DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }\r\n",
      "               DATA {\r\n",
      "               (0): 4, 4\r\n",
      "               }\r\n",
      "            }\r\n",
      "            DATASET \"dset2\" {\r\n",
      "               DATATYPE  H5T_STD_I64LE\r\n",
      "               DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }\r\n",
      "               DATA {\r\n",
      "               (0): 5, 5\r\n",
      "               }\r\n",
      "            }\r\n",
      "         }\r\n",
      "      }\r\n",
      "   }\r\n",
      "}\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "f.close()\n",
    "!h5dump data.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File(\"data.hdf5\", 'r+')\n",
    "'data' in f # containership testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/group1/small' in f  # full path names works too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes\n",
    "All groups and datasets support attached named bits of data called attributes (i.e., metadata), dictionary-style objects. Attributes are a critical part of what makes HDF5 a self-describing format. \n",
    "\n",
    "Attributes have the following properties:\n",
    "* created from any scalar or NumPy array\n",
    "* small (generally < 64k)\n",
    "* no partial I/O (i.e. slicing); the entire attribute must be read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recall, dataset2 is the small array\n",
    "dataset2 = f['group1/small']\n",
    "dataset2.attrs['sampling rate'] = 10e5\n",
    "dataset2.attrs['task-type'] = 'rest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sampling rate', u'task-type']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'sampling rate', 1000000.0), (u'task-type', 'rest')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.attrs.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can also label the dimensions of a dataset\n",
    "f['group1/small'].dims[0].label = 'x'\n",
    "f['group1/small'].dims[1].label = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 \"data.hdf5\" {\r\n",
      "GROUP \"/\" {\r\n",
      "   GROUP \"group1\" {\r\n",
      "      DATASET \"small\" {\r\n",
      "         DATATYPE  H5T_IEEE_F64LE\r\n",
      "         DATASPACE  SIMPLE { ( 3, 3 ) / ( 3, 3 ) }\r\n",
      "         DATA {\r\n",
      "         (0,0): 0.643312, 0.944549, 0.901227,\r\n",
      "         (1,0): 0.641839, 0.185239, 0.302659,\r\n",
      "         (2,0): 0.855635, 0.159378, 0.941674\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"DIMENSION_LABELS\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE H5T_VARIABLE;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_ASCII;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }\r\n",
      "            DATA {\r\n",
      "            (0): \"x\", \"y\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"sampling rate\" {\r\n",
      "            DATATYPE  H5T_IEEE_F64LE\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): 1e+06\r\n",
      "            }\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"task-type\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE H5T_VARIABLE;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_ASCII;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"rest\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "      }\r\n",
      "      GROUP \"subgrp\" {\r\n",
      "      }\r\n",
      "   }\r\n",
      "   GROUP \"group2\" {\r\n",
      "      DATASET \"dset3\" {\r\n",
      "         DATATYPE  H5T_STD_I64LE\r\n",
      "         DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }\r\n",
      "         DATA {\r\n",
      "         (0): 6, 6\r\n",
      "         }\r\n",
      "      }\r\n",
      "      GROUP \"subgrp2\" {\r\n",
      "         GROUP \"anothergroup\" {\r\n",
      "            DATASET \"dset1\" {\r\n",
      "               DATATYPE  H5T_STD_I64LE\r\n",
      "               DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }\r\n",
      "               DATA {\r\n",
      "               (0): 4, 4\r\n",
      "               }\r\n",
      "            }\r\n",
      "            DATASET \"dset2\" {\r\n",
      "               DATATYPE  H5T_STD_I64LE\r\n",
      "               DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }\r\n",
      "               DATA {\r\n",
      "               (0): 5, 5\r\n",
      "               }\r\n",
      "            }\r\n",
      "         }\r\n",
      "      }\r\n",
      "   }\r\n",
      "}\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "f.close()\n",
    "!h5dump data.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What else can I do with HDF5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunking\n",
    "* Datasets created with the default settings will be contiguous (laid out on disk in traditional C order)\n",
    "* Datasets created with the chunked storage will be divided up into regularly-sized pieces which are stored haphazardly on disk, and indexed using a B-tree\n",
    "    * Recommended to keep larger chunks for larger datasets\n",
    "    * Note: when any element in a chunk is accessed, the entire chunk is read from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File(\"data2.hdf5\", 'w')\n",
    "# Set the keyword chunks to a tuple indicating the chunk shape:\n",
    "dset = f.create_dataset(\"chunked\", (1000, 1000), chunks=(100, 100))\n",
    "# In this case, data will be read and written in blocks with shape (100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let h5py decide your chunk shape\n",
    "dset = f.create_dataset(\"autochunk\", (1000, 1000), chunks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters\n",
    "Data is compressed on the way to disk and decompressed when read. Once the dataset is created with a particular compression filter applied, data may be read and written as normal with no special steps required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enable a specific type of compression\n",
    "dset = f.create_dataset(\"zipped\", (100, 100), compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel HDF5\n",
    "* It uses the MPI (Message Passing Interface) standard for interprocess communication accomplished through the mpi4py Python package.\n",
    "* To use parallel HDF5, must do a separate build, although a parallel version of HDF5 might be available through your package manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### More HDF5 Python Examples:\n",
    "https://www.hdfgroup.org/HDF5/examples/py.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
